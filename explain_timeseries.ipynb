{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Time-Series Electricity Consumption Prediction with SHAP Explanations\n",
        "\n",
        "This notebook demonstrates how to use the `timeseries.py` module to explain time-series predictions using SHAP (SHapley Additive exPlanations).\n",
        "\n",
        "SHAP provides a unified measure of feature importance that satisfies desirable properties like local accuracy and consistency."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add src folder to path\n",
        "import sys\n",
        "sys.path.insert(0, './src')\n",
        "\n",
        "# Import helper functions for data and model management\n",
        "from helpers.timeseries_data import (\n",
        "    generate_synthetic_electricity_data,\n",
        "    create_time_series_features,\n",
        "    prepare_train_test_split\n",
        ")\n",
        "\n",
        "from helpers.model_training import (\n",
        "    create_models,\n",
        "    train_model\n",
        ")\n",
        "\n",
        "# Import SHAP explainability functions\n",
        "from timeseries import (\n",
        "    compute_shap_values,\n",
        "    compute_feature_importance,\n",
        "    get_shap_summary_stats,\n",
        "    save_shap_summary_plot,\n",
        "    save_shap_waterfall_plot,\n",
        "    save_feature_importance_plot,\n",
        "    get_prediction_explanation,\n",
        "    save_results_summary,\n",
        "    explain_timeseries_predictions\n",
        ")\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Generate Synthetic Data\n",
        "\n",
        "Create a realistic time-series dataset with seasonal and weekly patterns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Step 1] Generating synthetic electricity consumption data...\n",
            "Generating synthetic electricity consumption data...\n",
            "Dataset shape: (720, 8)\n",
            "\n",
            "First few rows:\n",
            "             datetime  consumption  temperature  hour  day_of_week  \\\n",
            "0 2023-01-01 00:00:00   612.404915    21.662276     0            6   \n",
            "1 2023-01-01 01:00:00   614.282436    19.757341     1            6   \n",
            "2 2023-01-01 02:00:00   675.560280    22.115199     2            6   \n",
            "3 2023-01-01 03:00:00   883.838972    24.741223     3            6   \n",
            "4 2023-01-01 04:00:00   901.338134    19.469673     4            6   \n",
            "\n",
            "   day_of_year  month  is_weekend  \n",
            "0            1      1           1  \n",
            "1            1      1           1  \n",
            "2            1      1           1  \n",
            "3            1      1           1  \n",
            "4            1      1           1  \n",
            "\n",
            "Data summary:\n",
            "       consumption  temperature        hour  day_of_week\n",
            "count   720.000000   720.000000  720.000000   720.000000\n",
            "mean    991.605641    22.577184   11.500000     3.000000\n",
            "std     423.639109     3.279482    6.926999     2.083113\n",
            "min     244.005001    12.158465    0.000000     0.000000\n",
            "25%     640.416839    20.354211    5.750000     1.000000\n",
            "50%     904.331886    22.592669   11.500000     3.000000\n",
            "75%    1341.920379    24.719360   17.250000     5.000000\n",
            "max    2036.080535    33.101283   23.000000     6.000000\n"
          ]
        }
      ],
      "source": [
        "# Generate synthetic electricity consumption data\n",
        "print(\"[Step 1] Generating synthetic electricity consumption data...\")\n",
        "df = generate_synthetic_electricity_data(n_days=30)  # Using smaller dataset for notebook\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(df.head())\n",
        "print(f\"\\nData summary:\")\n",
        "print(df[['consumption', 'temperature', 'hour', 'day_of_week']].describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Feature Engineering\n",
        "\n",
        "Create lagged features, rolling statistics, and time-based features for time-series prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Step 2] Creating time-series features...\n",
            "Creating time-series features...\n",
            "Feature matrix shape: (552, 31)\n",
            "Number of features: 30\n",
            "\n",
            "Feature columns:\n",
            "['datetime', 'consumption', 'temperature', 'hour', 'day_of_week', 'day_of_year', 'month', 'is_weekend', 'lag_1h', 'lag_2h', 'lag_3h', 'lag_24h', 'lag_48h', 'lag_168h', 'rolling_mean_6h', 'rolling_std_6h', 'rolling_mean_12h', 'rolling_std_12h', 'rolling_mean_24h', 'rolling_std_24h', 'rolling_mean_48h', 'rolling_std_48h', 'hour_sin', 'hour_cos', 'day_of_week_sin', 'day_of_week_cos', 'month_sin', 'month_cos', 'temp_squared', 'temp_cooling_degree', 'temp_heating_degree']\n"
          ]
        }
      ],
      "source": [
        "# Engineer features for time-series modeling\n",
        "print(\"[Step 2] Creating time-series features...\")\n",
        "df_features = create_time_series_features(df, target_col='consumption')\n",
        "print(f\"Feature matrix shape: {df_features.shape}\")\n",
        "print(f\"Number of features: {len(df_features.columns) - 1}\")\n",
        "print(f\"\\nFeature columns:\")\n",
        "print(df_features.columns.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Train Multiple Models\n",
        "\n",
        "Compare predictions from different regression models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Step 3] Preparing data and creating models...\n",
            "Training set size: 441\n",
            "Test set size: 111\n",
            "Training set size: 441\n",
            "Test set size: 111\n",
            "\n",
            "Created models: ['Random Forest', 'Linear Regression']\n",
            "\n",
            "Training Random Forest...\n",
            "  Train MSE: 797.80, R²: 0.9958\n",
            "  Test MSE: 7347.18, R²: 0.9513\n",
            "\n",
            "Training Linear Regression...\n",
            "  Train MSE: 2303.51, R²: 0.9880\n",
            "  Test MSE: 3169.37, R²: 0.9790\n",
            "  Train MSE: 797.80, R²: 0.9958\n",
            "  Test MSE: 7347.18, R²: 0.9513\n",
            "\n",
            "Training Linear Regression...\n",
            "  Train MSE: 2303.51, R²: 0.9880\n",
            "  Test MSE: 3169.37, R²: 0.9790\n"
          ]
        }
      ],
      "source": [
        "# Split data and create models\n",
        "print(\"[Step 3] Preparing data and creating models...\")\n",
        "X_train, X_test, y_train, y_test, feature_cols = prepare_train_test_split(\n",
        "    df_features, target_col='consumption', test_size=0.2\n",
        ")\n",
        "print(f\"Training set size: {len(X_train)}\")\n",
        "print(f\"Test set size: {len(X_test)}\")\n",
        "\n",
        "# Create models\n",
        "models_dict = create_models(['randomforest', 'linear'])\n",
        "print(f\"\\nCreated models: {list(models_dict.keys())}\")\n",
        "\n",
        "# Train each model\n",
        "training_results = {}\n",
        "for model_name, model in models_dict.items():\n",
        "    result = train_model(model, X_train, y_train, X_test, y_test, model_name)\n",
        "    training_results[model_name] = result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Evaluate Models\n",
        "\n",
        "Assess model performance using MSE, R², and other metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Step 4] Model Performance Summary:\n",
            "\n",
            "Random Forest:\n",
            "  Train MSE: 797.80, R²: 0.9958\n",
            "  Test MSE:  7347.18, R²: 0.9513\n",
            "\n",
            "Linear Regression:\n",
            "  Train MSE: 2303.51, R²: 0.9880\n",
            "  Test MSE:  3169.37, R²: 0.9790\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Display model performance metrics\n",
        "print(\"[Step 4] Model Performance Summary:\")\n",
        "print()\n",
        "for model_name, result in training_results.items():\n",
        "    metrics = result['metrics']\n",
        "    print(f\"{model_name}:\")\n",
        "    print(f\"  Train MSE: {metrics['train_mse']:.2f}, R²: {metrics['train_r2']:.4f}\")\n",
        "    print(f\"  Test MSE:  {metrics['test_mse']:.2f}, R²: {metrics['test_r2']:.4f}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: SHAP Explanations\n",
        "\n",
        "Use SHAP to explain which features are most important for predictions from each model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Step 5] Computing SHAP explanations...\n",
            "\n",
            "\n",
            "Processing Random Forest...\n",
            "  Creating SHAP explainer for Random Forest...\n",
            "  SHAP Values Shape: (20, 29)\n",
            "  Mean |SHAP|: 12.783\n",
            "  Top 5 Features:\n",
            "    lag_168h: 300.0021\n",
            "    lag_1h: 12.5235\n",
            "    rolling_std_12h: 8.4451\n",
            "    hour_sin: 7.5591\n",
            "    rolling_mean_24h: 4.1362\n",
            "\n",
            "Processing Linear Regression...\n",
            "  Creating SHAP explainer for Linear Regression...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb6135053394449fb300dde0a27de971",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  SHAP Values Shape: (10, 29)\n",
            "  Mean |SHAP|: 55.391\n",
            "  Top 5 Features:\n",
            "    rolling_mean_6h: 643.8386\n",
            "    rolling_mean_12h: 385.6861\n",
            "    temp_squared: 92.5029\n",
            "    lag_3h: 89.4762\n",
            "    temp_cooling_degree: 80.9713\n"
          ]
        }
      ],
      "source": [
        "# Compute SHAP values for each model\n",
        "print(\"[Step 5] Computing SHAP explanations...\")\n",
        "print()\n",
        "shap_results = {}\n",
        "\n",
        "for model_name, model in models_dict.items():\n",
        "    print(f\"\\nProcessing {model_name}...\")\n",
        "    result = compute_shap_values(\n",
        "        model,\n",
        "        model_name,\n",
        "        X_train,\n",
        "        X_test,\n",
        "        num_samples=20\n",
        "    )\n",
        "    \n",
        "    if result:\n",
        "        shap_results[model_name] = result\n",
        "        \n",
        "        # Get feature importance\n",
        "        feature_importance = compute_feature_importance(\n",
        "            result['shap_values'],\n",
        "            result['X_sample'].columns\n",
        "        )\n",
        "        \n",
        "        # Get SHAP statistics\n",
        "        stats = get_shap_summary_stats(result['shap_values'])\n",
        "        \n",
        "        print(f\"  SHAP Values Shape: {stats['shape']}\")\n",
        "        print(f\"  Mean |SHAP|: {stats['mean_abs']:.3f}\")\n",
        "        print(f\"  Top 5 Features:\")\n",
        "        for idx, row in feature_importance.head(5).iterrows():\n",
        "            print(f\"    {row['feature']}: {row['importance']:.4f}\")\n",
        "    else:\n",
        "        print(f\"  Could not compute SHAP for {model_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Understanding SHAP Explanations\n",
        "\n",
        "### Key Concepts:\n",
        "\n",
        "1. **SHAP Values**: Measure each feature's contribution to the prediction\n",
        "   - Positive values: increase prediction\n",
        "   - Negative values: decrease prediction\n",
        "   - Magnitude: strength of impact\n",
        "\n",
        "2. **Summary Plot**: Shows the distribution of SHAP values for each feature\n",
        "   - Features at top have highest importance\n",
        "   - Color indicates feature value (high=red, low=blue)\n",
        "\n",
        "3. **Dependence Plot**: Shows how a feature's value affects its SHAP values\n",
        "   - Reveals non-linear relationships\n",
        "   - Helps identify feature interactions\n",
        "\n",
        "### Interpreting Results:\n",
        "\n",
        "- **Lagged Consumption Features**: Past electricity consumption is a strong predictor\n",
        "- **Rolling Averages**: Weekly and daily averages capture seasonal patterns\n",
        "- **Time Features**: Hour of day and day of week encode important patterns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Visualization - Summary Plots\n",
        "\n",
        "Save SHAP summary plots to visualize feature importance distributions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Step 6] Saving SHAP summary visualizations...\n",
            "\n",
            "Creating visualizations for Random Forest...\n",
            "  ✓ Saved summary plot: ./outputs/timeseries/Random Forest_shap_summary.png\n",
            "  ✓ Saved feature importance plot: ./outputs/timeseries/Random Forest_feature_importance.png\n",
            "Creating visualizations for Linear Regression...\n",
            "  ✓ Saved summary plot: ./outputs/timeseries/Linear Regression_shap_summary.png\n",
            "  ✓ Saved feature importance plot: ./outputs/timeseries/Random Forest_feature_importance.png\n",
            "Creating visualizations for Linear Regression...\n",
            "  ✓ Saved summary plot: ./outputs/timeseries/Linear Regression_shap_summary.png\n",
            "  ✓ Saved feature importance plot: ./outputs/timeseries/Linear Regression_feature_importance.png\n",
            "  ✓ Saved feature importance plot: ./outputs/timeseries/Linear Regression_feature_importance.png\n"
          ]
        }
      ],
      "source": [
        "# Save summary plots for each model\n",
        "import os\n",
        "print(\"[Step 6] Saving SHAP summary visualizations...\")\n",
        "print()\n",
        "\n",
        "output_dir = './outputs/timeseries'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for model_name, shap_data in shap_results.items():\n",
        "    print(f\"Creating visualizations for {model_name}...\")\n",
        "    \n",
        "    # Save summary plot\n",
        "    summary_output = os.path.join(output_dir, f'{model_name}_shap_summary.png')\n",
        "    save_shap_summary_plot(\n",
        "        shap_data['shap_values'],\n",
        "        shap_data['X_sample'],\n",
        "        summary_output,\n",
        "        model_name\n",
        "    )\n",
        "    print(f\"  ✓ Saved summary plot: {summary_output}\")\n",
        "    \n",
        "    # Save feature importance plot\n",
        "    feature_imp = compute_feature_importance(\n",
        "        shap_data['shap_values'],\n",
        "        shap_data['X_sample'].columns\n",
        "    )\n",
        "    imp_output = os.path.join(output_dir, f'{model_name}_feature_importance.png')\n",
        "    save_feature_importance_plot(feature_imp, imp_output, top_n=15)\n",
        "    print(f\"  ✓ Saved feature importance plot: {imp_output}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Individual Prediction Explanations\n",
        "\n",
        "Explain individual predictions using waterfall plots and detailed breakdowns.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Step 7] Explaining individual predictions...\n",
            "\n",
            "\n",
            "Random Forest - Sample Explanations:\n",
            "============================================================\n",
            "\n",
            "Sample Index 0 (of 20):\n",
            "  Predicted: 1705.86\n",
            "  Actual: 0.75\n",
            "  Error: 1705.11\n",
            "  Top Contributing Features:\n",
            "    lag_168h: +629.0347\n",
            "    temperature: +10.0653\n",
            "    temp_cooling_degree: +8.4069\n",
            "    temp_squared: +7.9650\n",
            "    lag_1h: +7.0206\n",
            "  ✓ Saved waterfall plot: ./outputs/timeseries/Random Forest_waterfall_sample.png\n",
            "\n",
            "Sample Index 10 (of 20):\n",
            "  Predicted: 619.71\n",
            "  Actual: -1.01\n",
            "  Error: 620.71\n",
            "  Top Contributing Features:\n",
            "    lag_168h: -398.7914\n",
            "    lag_1h: -14.1958\n",
            "    rolling_mean_24h: +9.6605\n",
            "    hour_sin: -8.4446\n",
            "    rolling_std_48h: +4.4244\n",
            "\n",
            "Linear Regression - Sample Explanations:\n",
            "============================================================\n",
            "\n",
            "Sample Index 0 (of 10):\n",
            "  Predicted: 1713.00\n",
            "  Actual: -1.21\n",
            "  Error: 1714.21\n",
            "  Top Contributing Features:\n",
            "    rolling_mean_6h: +1196.6963\n",
            "    rolling_mean_12h: -425.0115\n",
            "    temp_squared: -160.2524\n",
            "    temp_cooling_degree: +159.8309\n",
            "    lag_3h: -140.9400\n",
            "  ✓ Saved waterfall plot: ./outputs/timeseries/Linear Regression_waterfall_sample.png\n",
            "\n",
            "Sample Index 5 (of 10):\n",
            "  Predicted: 1095.21\n",
            "  Actual: 0.77\n",
            "  Error: 1094.45\n",
            "  Top Contributing Features:\n",
            "    rolling_mean_6h: +562.1631\n",
            "    rolling_mean_12h: -445.5083\n",
            "    temp_squared: -250.4832\n",
            "    temp_cooling_degree: +223.3060\n",
            "    temperature: +143.6692\n",
            "  ✓ Saved waterfall plot: ./outputs/timeseries/Linear Regression_waterfall_sample.png\n",
            "\n",
            "Sample Index 5 (of 10):\n",
            "  Predicted: 1095.21\n",
            "  Actual: 0.77\n",
            "  Error: 1094.45\n",
            "  Top Contributing Features:\n",
            "    rolling_mean_6h: +562.1631\n",
            "    rolling_mean_12h: -445.5083\n",
            "    temp_squared: -250.4832\n",
            "    temp_cooling_degree: +223.3060\n",
            "    temperature: +143.6692\n"
          ]
        }
      ],
      "source": [
        "# Explain individual predictions\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "print(\"[Step 7] Explaining individual predictions...\")\n",
        "print()\n",
        "\n",
        "for model_name, shap_data in shap_results.items():\n",
        "    print(f\"\\n{model_name} - Sample Explanations:\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    X_sample = shap_data['X_sample']\n",
        "    shap_vals = shap_data['shap_values']\n",
        "    \n",
        "    # Create dummy y values for demonstration (same length as X_sample)\n",
        "    y_sample = pd.Series(np.random.randn(len(X_sample)), index=range(len(X_sample)))\n",
        "    \n",
        "    # Use valid indices: first and middle samples\n",
        "    sample_indices = [0, len(X_sample)//2]\n",
        "    \n",
        "    for sample_idx in sample_indices:\n",
        "        # Get detailed explanation for this prediction\n",
        "        explanation = get_prediction_explanation(\n",
        "            models_dict[model_name],\n",
        "            shap_vals,\n",
        "            X_sample,\n",
        "            y_sample,\n",
        "            sample_idx=sample_idx,\n",
        "            top_n=5\n",
        "        )\n",
        "        \n",
        "        print(f\"\\nSample Index {sample_idx} (of {len(X_sample)}):\")\n",
        "        print(f\"  Predicted: {explanation['predicted']:.2f}\")\n",
        "        print(f\"  Actual: {explanation['actual']:.2f}\")\n",
        "        print(f\"  Error: {explanation['error']:.2f}\")\n",
        "        print(f\"  Top Contributing Features:\")\n",
        "        for _, row in explanation['top_features'].iterrows():\n",
        "            print(f\"    {row['feature']}: {row['shap_value']:+.4f}\")\n",
        "        \n",
        "        # Save waterfall plot for first sample of each model\n",
        "        if sample_idx == 0:\n",
        "            waterfall_output = os.path.join(output_dir, f'{model_name}_waterfall_sample.png')\n",
        "            save_shap_waterfall_plot(\n",
        "                shap_data['explainer'],\n",
        "                shap_data['shap_values'],\n",
        "                X_sample,\n",
        "                waterfall_output,\n",
        "                sample_idx=0\n",
        "            )\n",
        "            print(f\"  ✓ Saved waterfall plot: {waterfall_output}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Save Results Summary\n",
        "\n",
        "Create a comprehensive summary report of all analyses.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Step 8] Saving results summary...\n",
            "\n",
            "✓ Saved results summary: ./outputs/timeseries/analysis_summary.txt\n",
            "\n",
            "Summary Statistics:\n",
            "------------------------------------------------------------\n",
            "\n",
            "Random Forest:\n",
            "  Test R²: 0.9513\n",
            "  Test MSE: 7347.18\n",
            "  Mean |SHAP|: 12.7825\n",
            "\n",
            "Linear Regression:\n",
            "  Test R²: 0.9790\n",
            "  Test MSE: 3169.37\n",
            "  Mean |SHAP|: 55.3914\n"
          ]
        }
      ],
      "source": [
        "# Save comprehensive results summary\n",
        "print(\"[Step 8] Saving results summary...\")\n",
        "print()\n",
        "\n",
        "# Prepare results dictionary\n",
        "results = {\n",
        "    'models': list(models_dict.keys()),\n",
        "    'training_results': training_results,\n",
        "    'shap_results': {\n",
        "        model_name: {\n",
        "            'shape': shap_data['shap_values'].shape,\n",
        "            'mean_abs': float(np.abs(shap_data['shap_values']).mean()),\n",
        "            'std': float(np.std(shap_data['shap_values'])),\n",
        "        }\n",
        "        for model_name, shap_data in shap_results.items()\n",
        "    },\n",
        "    'feature_importance': {\n",
        "        model_name: compute_feature_importance(\n",
        "            shap_data['shap_values'],\n",
        "            shap_data['X_sample'].columns\n",
        "        ).to_dict()\n",
        "        for model_name, shap_data in shap_results.items()\n",
        "    }\n",
        "}\n",
        "\n",
        "# Save summary report\n",
        "summary_output = os.path.join(output_dir, 'analysis_summary.txt')\n",
        "save_results_summary(results, summary_output)\n",
        "print(f\"✓ Saved results summary: {summary_output}\")\n",
        "print()\n",
        "\n",
        "# Display summary statistics\n",
        "print(\"Summary Statistics:\")\n",
        "print(\"-\" * 60)\n",
        "for model_name, metrics in results['training_results'].items():\n",
        "    print(f\"\\n{model_name}:\")\n",
        "    print(f\"  Test R²: {metrics['metrics']['test_r2']:.4f}\")\n",
        "    print(f\"  Test MSE: {metrics['metrics']['test_mse']:.2f}\")\n",
        "    if model_name in results['shap_results']:\n",
        "        print(f\"  Mean |SHAP|: {results['shap_results'][model_name]['mean_abs']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: High-Level Function - One-Shot Analysis\n",
        "\n",
        "Use the high-level orchestrator function to run complete analysis in one call.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Step 9] High-Level Analysis - One-Shot Approach\n",
            "============================================================\n",
            "\n",
            "The 'explain_timeseries_predictions' function handles all steps:\n",
            "1. Data generation and feature engineering\n",
            "2. Model training\n",
            "3. SHAP value computation\n",
            "4. Visualization generation\n",
            "5. Results summary\n",
            "\n",
            "Example usage:\n",
            "\n",
            "from timeseries import explain_timeseries_predictions\n",
            "\n",
            "results = explain_timeseries_predictions(\n",
            "    n_days=30,                          # Data size\n",
            "    model_types=['randomforest', 'linear'],  # Models to train\n",
            "    n_samples=20,                       # SHAP samples\n",
            "    output_dir='./analysis_output'      # Where to save results\n",
            ")\n",
            "\n",
            "# Results contain everything needed for further analysis\n",
            "print(results['model_performance'])\n",
            "print(results['feature_importance'])\n",
            "\n",
            "\n",
            "Note: This function is ideal for batch analyses or automation.\n"
          ]
        }
      ],
      "source": [
        "# Demonstrate the high-level orchestrator function\n",
        "print(\"[Step 9] High-Level Analysis - One-Shot Approach\")\n",
        "print(\"=\" * 60)\n",
        "print()\n",
        "print(\"The 'explain_timeseries_predictions' function handles all steps:\")\n",
        "print(\"1. Data generation and feature engineering\")\n",
        "print(\"2. Model training\")\n",
        "print(\"3. SHAP value computation\")\n",
        "print(\"4. Visualization generation\")\n",
        "print(\"5. Results summary\")\n",
        "print()\n",
        "\n",
        "# This is how users can run the entire analysis in one call:\n",
        "print(\"Example usage:\")\n",
        "print(\"\"\"\n",
        "from timeseries import explain_timeseries_predictions\n",
        "\n",
        "results = explain_timeseries_predictions(\n",
        "    n_days=30,                          # Data size\n",
        "    model_types=['randomforest', 'linear'],  # Models to train\n",
        "    n_samples=20,                       # SHAP samples\n",
        "    output_dir='./analysis_output'      # Where to save results\n",
        ")\n",
        "\n",
        "# Results contain everything needed for further analysis\n",
        "print(results['model_performance'])\n",
        "print(results['feature_importance'])\n",
        "\"\"\")\n",
        "\n",
        "print()\n",
        "print(\"Note: This function is ideal for batch analyses or automation.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Available Functions Reference\n",
        "\n",
        "### Data & Model Preparation (helpers)\n",
        "- `generate_synthetic_electricity_data()` - Create realistic time-series data\n",
        "- `create_time_series_features()` - Engineer lagged and rolling features\n",
        "- `prepare_train_test_split()` - Split and prepare data\n",
        "- `create_models()` - Create multiple regression models\n",
        "- `train_model()` - Train and evaluate a model\n",
        "\n",
        "### Explainability Functions (timeseries.py)\n",
        "1. **`compute_shap_values()`** - Compute SHAP explanations\n",
        "2. **`compute_feature_importance()`** - Calculate feature importance from SHAP values\n",
        "3. **`get_shap_summary_stats()`** - Get statistical summaries\n",
        "4. **`save_shap_summary_plot()`** - Visualize SHAP value distributions\n",
        "5. **`save_shap_waterfall_plot()`** - Plot individual prediction breakdowns\n",
        "6. **`save_feature_importance_plot()`** - Rank and visualize top features\n",
        "7. **`get_prediction_explanation()`** - Get detailed prediction analysis\n",
        "8. **`save_results_summary()`** - Generate comprehensive summary report\n",
        "9. **`explain_timeseries_predictions()`** - One-shot analysis orchestrator\n",
        "\n",
        "### Typical Workflow\n",
        "1. Generate/load data → `generate_synthetic_electricity_data()`\n",
        "2. Create features → `create_time_series_features()`\n",
        "3. Split data → `prepare_train_test_split()`\n",
        "4. Create models → `create_models()`\n",
        "5. Train models → `train_model()`\n",
        "6. Compute SHAP → `compute_shap_values()`\n",
        "7. Analyze → `compute_feature_importance()`, `get_prediction_explanation()`\n",
        "8. Visualize → `save_shap_summary_plot()`, `save_feature_importance_plot()`\n",
        "9. Report → `save_results_summary()`\n",
        "\n",
        "Or use `explain_timeseries_predictions()` to do all steps automatically.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Concepts and Interpretations\n",
        "\n",
        "### Understanding SHAP Values\n",
        "- **Positive values**: Feature increases the prediction\n",
        "- **Negative values**: Feature decreases the prediction\n",
        "- **Magnitude**: Strength of the effect\n",
        "\n",
        "### Reading Summary Plots\n",
        "- **Features on top**: Most important for model\n",
        "- **Red points**: High feature values\n",
        "- **Blue points**: Low feature values\n",
        "- **Position on x-axis**: Impact direction\n",
        "\n",
        "### Waterfall Plots\n",
        "- **Base value**: Model's average prediction\n",
        "- **Arrows**: Feature contributions (up/down)\n",
        "- **Final prediction**: Sum of all contributions\n",
        "\n",
        "### Feature Importance Types\n",
        "- **SHAP-based**: Considers all features for all predictions\n",
        "- **Global**: What features matter on average\n",
        "- **Local**: What features matter for one prediction\n",
        "\n",
        "### Time-Series Specifics\n",
        "- **Lagged features**: Past values are often most important\n",
        "- **Rolling averages**: Capture trends and patterns\n",
        "- **Time features**: Hour/day encode important seasonality\n",
        "- **Recent vs. historical**: Recency often weights more heavily\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "\n",
        "1. **Analyze Different Time Periods**: Compare explanations for different seasons\n",
        "2. **Add Real Data**: Replace synthetic data with actual electricity consumption data\n",
        "3. **Feature Selection**: Use SHAP values to select most important features\n",
        "4. **Model Improvement**: Focus on features identified as important by SHAP\n",
        "5. **Uncertainty Estimation**: Add confidence intervals to predictions"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
